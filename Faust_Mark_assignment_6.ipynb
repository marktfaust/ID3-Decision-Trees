{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #6\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Read the entire notebook before beginning your work, \n",
    "02. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "03. Each helper function should be preceeded by documentation (Markdown cell),\n",
    "04. No comments in the code; anything worth mentioning should be included in the documentation,\n",
    "05. Use descriptive variable names,\n",
    "06. Functions should do only one thing,\n",
    "07. Check submission deadline on Gradescope, \n",
    "08. Rename the file to Last_First_assignment_6, \n",
    "09. Submit your notebook (as .ipynb, not PDF) using Gradescope, \n",
    "10. Do not submit any other files, and\n",
    "11. **Do not use any AI/ML libraries, packages, such as pandas, scikit (numpy is fine)**\n",
    "\n",
    "## Directions _not_ applicable for this Assignment:\n",
    "* Do not use classes,\n",
    "* Keep functions to 20 lines or less (including empty lines so do not add any),\n",
    "* Each helper function should be followed by three assert-style unit tests.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment we will implement a Decision Tree using the ID3 Algorithm. The goal is classify a mushroom as either edible ('e') or poisonous ('p'). Dataset has been uploaded to Canvas. In case you'd like to learn more about it, here's the link to the repo: https://archive.ics.uci.edu/dataset/73/mushroom. \n",
    "\n",
    "\n",
    "Our  Decision Tree pipeline is as follows:\n",
    "\n",
    "\n",
    "1) `cross_validate` will take data (supplied as folds using 10 fold cross validation) and do the following:\n",
    "* For each setting of depth limit (the hyperparameter in decision trees, including 0)\n",
    "* * and for each fold of data\n",
    "* * * use `create_train_test` to split current fold into train and test\n",
    "* * * call `train` to build and return a decision tree, \n",
    "* * * call `classify` to use the tree to get classifications,\n",
    "* * * call `evaluate` to compare classifications to the actual answers (ground truth),\n",
    "* * * Print the performance for that fold\n",
    "* * Summarize the performance for that depth limit over all folds using `get_stats`\n",
    "\n",
    "\n",
    "2) `pretty_print_tree(tree)` will print what the tree looks like when using the **entire** data set (no train/test split) with depth limit set to None.\n",
    "\n",
    "\n",
    "All the code in this pipeline has been provided, except for a working `train` function. The `train` function currently returns a hard-coded tree from our lecture. Don't do that. Use ID3 to build your tree and use the depth limit to stop. When you're train function is complete, it should work for the lecture data, and mushrooms. Although `train` is terrible right now, pay attention to how the tree is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Note</strong>\n",
    "    <p>\n",
    "        Let's start with our example from the 06-Nov lecture. Target variable is Safe?, which can be yes or no. Anything *_lecture refers to the dataset we walked through in class.  \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lecture = [['round','large','blue','no'],\n",
    "['square','large','green','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','blue','no'],\n",
    "['round','small','blue','no'],\n",
    "['round','small','red','yes'],\n",
    "['square','small','green','no'],\n",
    "['round','large','green','yes'],\n",
    "['square','large','green','yes'],\n",
    "['square','large','red','no'],\n",
    "['square','large','green','yes'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','small','green','no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['round', 'large', 'blue', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(data_lecture[0]) # a record of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_lecture = ['shape', \n",
    "                      'size', \n",
    "                      'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_folds\"></a>\n",
    "## create_folds\n",
    "\n",
    "\n",
    "With n-fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. For data set with 100 observations (or records), n set to 10 would have 10 observations in each fold.\n",
    "\n",
    "* **data** List: a list (data_lecture, for instance)\n",
    "* **n** int: number of folds\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_lecture = create_folds(data=data_lecture, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_train_test\"></a>\n",
    "## create_train_test\n",
    "\n",
    "\n",
    "This function takes the n folds and returns the train and test sets. One of the n folds is used to test, the others are used for training.\n",
    "\n",
    "* **folds** List[List[List]]: see `create_folds`\n",
    "* **index** int: fold index that is used for testing\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 0) # test data is folds_lecture index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 1) # test data is folds_lecture index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's load the mushroom data.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parse_data\"></a>\n",
    "## parse_data\n",
    "\n",
    "Opens a file, splits on comma, and shuffles data before returning as a List of list. \n",
    "\n",
    "* **file_name** Str: filename for data\n",
    "\n",
    "\n",
    "**returns** \n",
    "Data as a list of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = parse_data(\"agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        We're going to move the target column (mushroom edible or poisonous) to the last column to match the lecture's format, where Safe? was at the end.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = [record[1:]+[record[0]] for record in data_mushroom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'f', 'g', 't', 'n', 'f', 'c', 'b', 'p', 't', 'b', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'n', 'v', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(data_mushroom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_mushroom = ['cap-shape',\n",
    "                   'cap-surface',\n",
    "                   'cap-color',\n",
    "                   'bruises?',\n",
    "                   'odor',\n",
    "                   'gill-attachment',\n",
    "                   'gill-spacing',\n",
    "                   'gill-size',\n",
    "                   'gill-color',\n",
    "                   'stalk-shape',\n",
    "                   'stalk-root',\n",
    "                   'stalk-surface-above-ring',\n",
    "                   'stalk-surface-below-ring',\n",
    "                   'stalk-color-above-ring',\n",
    "                   'stalk-color-below-ring',\n",
    "                   'veil-type',\n",
    "                   'veil-color',\n",
    "                   'ring-number',\n",
    "                   'ring-type',\n",
    "                   'spore-print-color',\n",
    "                   'population',\n",
    "                   'habitat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Class DOCUMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, title, depth, attribute_index=None, is_leaf=False):\n",
    "        self.__title = title\n",
    "        self.__depth = depth\n",
    "        self.__attribute_index = attribute_index\n",
    "        self.__is_leaf = is_leaf\n",
    "        self.__parent = None\n",
    "        self.__children = {}\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.__is_leaf\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self.__title\n",
    "    \n",
    "    def get_attribute_index(self):\n",
    "        return self.__attribute_index\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.__children.items()\n",
    "        \n",
    "    def set_parent(self, node):\n",
    "        self.__parent = node\n",
    "        \n",
    "    def set_child(self, value, node):\n",
    "        self.__children[value] = node\n",
    "        \n",
    "    def display(self):\n",
    "        print('Title:', self.__title)\n",
    "        print('Depth:', self.__depth)\n",
    "        print('Attribute_Index:', self.__attribute_index)\n",
    "        print('Is_Leaf:', self.__is_leaf)\n",
    "        print('Parent:', self.__parent)\n",
    "        print('Children:\\n')\n",
    "        for value, child in self.__children.items():\n",
    "            print('Value:', value)\n",
    "            child.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_answers\"></a>\n",
    "## get_answers\n",
    "\n",
    "This function extracts a list of the target values from data. The function assumes the target variable is the last column of the data.\n",
    "\n",
    "* **data** List[List]: The data provided in a list of list format identical to the structure of `data_lecture` or `data_mushroom`\n",
    "\n",
    "\n",
    "**returns** \n",
    "A list of the values of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(data):\n",
    "    return [record[-1] for record in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_answers([]) == []\n",
    "assert get_answers(data_lecture) == ['no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_mode\"></a>\n",
    "## get_mode\n",
    "\n",
    "This function finds the mode of a list of items. \n",
    "\n",
    "* **answers** List: A list of items\n",
    "\n",
    "**returns** \n",
    "The item that appears the most often in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(answers):\n",
    "    count_dict = {}\n",
    "    for answer in answers:\n",
    "        if answer in count_dict:\n",
    "            count_dict[answer] = count_dict[answer] + 1\n",
    "        else:\n",
    "            count_dict[answer] = 1\n",
    "    mode_count = max(count_dict.values())\n",
    "    mode = [k for k, v in count_dict.items() if v == mode_count]\n",
    "    return mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_mode(['no', 'no', 'no', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'no', 'yes', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'yes', 'yes', 'yes']) == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_structured_data\"></a>\n",
    "## get_structured_data\n",
    "\n",
    "This function converts a 2D list or array of raw data into a structured numpy array, where each column is labeled with a corresponding feature name.\n",
    "\n",
    "* **data** `List[List]` or `np.ndarray`: The raw data, where each inner list or row represents a data sample with feature values.\n",
    "* **feature_names** `List[str]`: A list of feature names corresponding to the columns of `data`. The function will append 'y' as the name of the target variable automatically.\n",
    "\n",
    "**returns** \n",
    "* **structured_data** `np.ndarray`: A structured numpy array with each element labeled by the feature names and the target variable `y`.\n",
    "\n",
    "The function creates a structured array by mapping each row of the input data to a tuple and defining the data type for each column using the provided feature names plus the target variable `y`. Each feature and the target are represented as a string with a single Unicode character (`'U16'` data type).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structured_data(data, feature_names):\n",
    "    return np.array([tuple(data_sample) for data_sample in data], dtype=[(name, 'U16') for name in (feature_names + [('y')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"calculate_entropy\"></a>\n",
    "## calculate_entropy\n",
    "\n",
    "This function calculates the entropy of a dataset, which is a measure of the uncertainty or impurity in the dataset.\n",
    "\n",
    "* **counts** `np.ndarray`: An array representing the counts of each unique value in the target variable or subset of the data.\n",
    "* **length** `int`: The total number of observations in the dataset or subset of the data.\n",
    "\n",
    "**returns** \n",
    "* **entropy** `float`: The calculated entropy value based on the given counts and total number of observations.\n",
    "\n",
    "The function computes the entropy by first calculating the proportion of each count relative to the total number of observations. It then iterates through these proportions, accumulating the entropy using the formula \\( -\\sum p(x) \\log_2 p(x) \\), where \\( p(x) \\) is the proportion of each unique value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(counts, length):\n",
    "    proportions = counts / length\n",
    "    entropy = 0\n",
    "    for proportion in proportions:\n",
    "        entropy -= proportion * np.log2(proportion)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"calculate_information_gain\"></a>\n",
    "## calculate_information_gain\n",
    "\n",
    "This function calculates the information gain of a given attribute in a dataset. Information gain measures the reduction in entropy achieved by partitioning the data based on an attribute.\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset, including both features and the target variable `y`.\n",
    "* **attribute_name** `str`: The name of the attribute/feature in the dataset for which the information gain is being calculated.\n",
    "* **baseline_entropy** `float`: The entropy of the entire dataset (before partitioning).\n",
    "\n",
    "**returns** \n",
    "* **information_gain** `float`: The calculated information gain after partitioning the dataset based on the specified attribute.\n",
    "\n",
    "The function works by iterating through each unique value of the given attribute, calculating the entropy for each subset of data where the attribute takes that value, and computing a weighted average of those entropies. The final result is the difference between the baseline entropy and the weighted average, representing the information gain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(data, attribute_name, baseline_entropy):\n",
    "    values, counts = np.unique(data[attribute_name], return_counts=True)\n",
    "    counts_dict = dict(zip(values, counts))\n",
    "    entropies = {}\n",
    "    \n",
    "    for value in values:\n",
    "        mask = data[attribute_name] == value\n",
    "        selected_targets = data['y'][mask]\n",
    "        targets, target_counts = np.unique(selected_targets, return_counts=True)\n",
    "        entropies[value] = calculate_entropy(target_counts, counts_dict[value])\n",
    "        \n",
    "    weighted_average = 0\n",
    "    for value, entropy in entropies.items():\n",
    "        weight = counts_dict[value] / len(data[attribute_name])\n",
    "        weighted_average += weight * entropy\n",
    "    \n",
    "    return baseline_entropy - weighted_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pick_best_attribute\"></a>\n",
    "## pick_best_attribute\n",
    "\n",
    "This function selects the best attribute for splitting the data by calculating the information gain for each attribute and returning the attribute with the highest information gain.\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset, including both features and the target variable `y`.\n",
    "* **attributes** `List[str]`: A list of attribute names to be evaluated for information gain.\n",
    "\n",
    "**returns** \n",
    "* **best_attribute** `str`: The name of the attribute with the highest information gain.\n",
    "\n",
    "The function first calculates the baseline entropy of the target variable `y` in the dataset. It then iterates over each attribute provided in `attributes`, calculating the information gain for each one using `calculate_information_gain()`. Finally, it returns the attribute that yields the highest information gain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attribute(data, attributes):\n",
    "    values, counts = np.unique(data['y'], return_counts=True)\n",
    "    baseline_entropy = calculate_entropy(counts, len(data['y']))\n",
    "    \n",
    "    information_gains = {}\n",
    "    for attribute_name in attributes:\n",
    "        information_gains[attribute_name] = calculate_information_gain(data, attribute_name, baseline_entropy)\n",
    "    \n",
    "    return max(information_gains, key=information_gains.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_is_homogeneous\"></a>\n",
    "## data_is_homogeneous\n",
    "\n",
    "This function checks whether the target variable `y` in a given dataset is homogeneous, i.e., all target values are the same.\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset, which includes the target variable `y`.\n",
    "\n",
    "**returns** \n",
    "* **is_homogeneous** `bool`: `True` if the data is homogeneous (i.e., all target values are the same), otherwise `False`.\n",
    "\n",
    "The function calculates the entropy of the target variable `y` using `calculate_entropy()`. If the entropy is zero, it means there is no uncertainty, indicating that the data is homogeneous. An assertion is included to ensure the input dataset is not empty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_is_homogeneous(data):\n",
    "    assert len(data['y']) > 0\n",
    "    values, counts = np.unique(data['y'], return_counts=True)\n",
    "    baseline_entropy = calculate_entropy(counts, len(data['y']))\n",
    "    return baseline_entropy == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_values\"></a>\n",
    "## get_values\n",
    "\n",
    "This function retrieves the unique values for a specified attribute in the dataset, excluding any missing or placeholder values (e.g., '?').\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset.\n",
    "* **attribute_name** `str`: The name of the attribute for which unique values are to be retrieved.\n",
    "\n",
    "**returns** \n",
    "* **values** `np.ndarray`: An array of unique values for the specified attribute, with any placeholder values (e.g., '?') excluded.\n",
    "\n",
    "The function uses `np.unique()` to find the unique values in the specified attribute and filters out any values that are equal to the placeholder character (`'?'`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(data, attribute_name):\n",
    "    values = np.unique(data[attribute_name])\n",
    "    return values[values != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_subset_with_attribute_value\"></a>\n",
    "## get_subset_with_attribute_value\n",
    "\n",
    "This function extracts a subset of the dataset where the specified attribute has a given value.\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset.\n",
    "* **attribute_name** `str`: The name of the attribute used to filter the data.\n",
    "* **value** `str` or `any`: The value of the attribute that should be matched in the subset.\n",
    "\n",
    "**returns** \n",
    "* **subset** `np.ndarray`: A structured numpy array containing only the rows where the specified attribute has the given value.\n",
    "\n",
    "The function creates a mask by comparing the specified attribute to the given value and applies it to the dataset to return the filtered subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_with_attribute_value(data, attribute_name, value):\n",
    "    mask = data[attribute_name] == value\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dictionaried_tree\"></a>\n",
    "## dictionaried_tree\n",
    "\n",
    "This function converts a decision tree represented by `Node` objects into a nested dictionary structure for easier interpretation and visualization.\n",
    "\n",
    "* **node** `Node`: The root `Node` object of the decision tree.\n",
    "\n",
    "**returns** \n",
    "* **tree_dict** `Dict`: A nested dictionary representation of the decision tree. Each key in the dictionary is a tuple of the form `(attribute_name, attribute_index, attribute_value)`, and the corresponding value is either another nested dictionary or a label if the node is a leaf.\n",
    "\n",
    "The function recursively traverses the tree, converting each non-leaf `Node` into a dictionary where the keys represent the attribute and its corresponding value, and the values are either sub-trees or the final labels for leaf nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionaried_tree(node):\n",
    "    if node.is_leaf(): return node.get_title()\n",
    "    dictionary = {}\n",
    "    for value, child in node.get_children():\n",
    "        dictionary[(node.get_title(), node.get_attribute_index(), value)] = dictionaried_tree(child)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"print_nested_dict\"></a>\n",
    "## print_nested_dict\n",
    "\n",
    "This function prints a nested dictionary in a formatted and indented style for better readability.\n",
    "\n",
    "* **d** `Dict`: The nested dictionary to be printed.\n",
    "* **indent** `int`: The number of spaces for indentation (used for recursive calls). Defaults to 0.\n",
    "* **is_first_level** `bool`: A flag indicating whether the current level is the top level of the dictionary. Defaults to `True`.\n",
    "\n",
    "**returns** \n",
    "* None: This function prints the formatted nested dictionary directly to the console.\n",
    "\n",
    "The function recursively traverses the nested dictionary, printing keys and values with appropriate indentation. If a value is another dictionary, it calls itself to print the nested structure. This creates a human-readable output that helps visualize complex dictionary structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_dict(d, indent=0, is_first_level=True):\n",
    "    if is_first_level:\n",
    "        print(' ' * indent + '{')\n",
    "    else:\n",
    "        print(' {', end='')\n",
    "\n",
    "    first = True\n",
    "    for key, value in d.items():\n",
    "        if not first:\n",
    "            print(',', end='')\n",
    "        first = False\n",
    "        print()\n",
    "        print(' ' * (indent + 4) + repr(key) + ': ', end='')\n",
    "        if isinstance(value, dict):\n",
    "            print_nested_dict(value, indent + 4, is_first_level=False)\n",
    "        else:\n",
    "            print(repr(value), end='')\n",
    "\n",
    "    print()\n",
    "    if is_first_level:\n",
    "        print(' ' * indent + '}')\n",
    "    else:\n",
    "        print(' ' * indent + '}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "## id3\n",
    "\n",
    "This function implements the ID3 (Iterative Dichotomiser 3) algorithm for training a decision tree based on a dataset and a set of attributes. The algorithm recursively selects the best attribute to split the data until certain stopping conditions are met.\n",
    "\n",
    "* **data** `np.ndarray`: A structured numpy array representing the dataset, including features and the target variable `y`.\n",
    "* **attributes** `List[str]`: A list of attribute names used for splitting the data.\n",
    "* **default** `str` or `any`: The default label returned if the dataset is empty.\n",
    "* **depth** `int`: The current depth of the tree.\n",
    "* **depth_limit** `int` or `None`: An optional depth limit for the tree. If `None`, the tree can grow indefinitely; otherwise, the tree stops splitting when the limit is reached.\n",
    "\n",
    "**returns** \n",
    "* **node** `Node`: A `Node` object representing the root of the trained decision tree or a subtree.\n",
    "\n",
    "**Functionality**:\n",
    "- **Base Cases**:\n",
    "  - Returns a leaf `Node` with the `default` label if the dataset is empty.\n",
    "  - Returns a leaf `Node` with the label of the first target value if the data is homogeneous (all `y` values are the same).\n",
    "  - Returns a leaf `Node` with the mode of `y` if there are no more attributes to split on.\n",
    "- **Recursive Step**:\n",
    "  - Selects the best attribute to split the data using `pick_best_attribute()`.\n",
    "  - Creates a `Node` for the chosen attribute.\n",
    "  - Iterates over each unique value of the attribute, creating a subset of the data where the attribute matches the value.\n",
    "  - Recursively calls `id3()` to build child nodes and sets them as children of the current `Node`.\n",
    "\n",
    "The function builds the decision tree until a stopping condition is met or the optional `depth_limit` is reached. Each child node is linked to its parent, and the parent node holds references to all child nodes, forming the tree structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, attributes, default, depth, depth_limit=None):\n",
    "    \n",
    "    # Add depth limit functionality\n",
    "    if len(data) == 0: return Node(default, depth, is_leaf=True)\n",
    "    if data_is_homogeneous(data): return Node(data['y'][0], depth, is_leaf=True)\n",
    "    if len(attributes) == 0 or depth_limit == depth: return Node(get_mode(data['y']), depth, is_leaf=True)\n",
    "    \n",
    "    best_attribute = pick_best_attribute(data, attributes)\n",
    "    \n",
    "    all_attributes = np.array(data.dtype.names)\n",
    "    attribute_index = np.where(all_attributes == best_attribute)[0][0]\n",
    "    \n",
    "    node = Node(best_attribute, depth, attribute_index=attribute_index)\n",
    "    \n",
    "    default_label = get_mode(data['y'])\n",
    "    \n",
    "    for value in get_values(data, best_attribute):\n",
    "        subset = get_subset_with_attribute_value(data, best_attribute, value)\n",
    "        child = id3(subset, [attribute for attribute in attributes if attribute != best_attribute], default_label, depth + 1, depth_limit)\n",
    "        child.set_parent(node)\n",
    "        node.set_child(value, child)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## train\n",
    "\n",
    "This function takes training_data, attribute names, and the depth limit and returns the decision tree as a nested dictionary. If the depth is 0, a dictionary is not returned. Instead, the mode of the target values is returned (i.e., majority class). \n",
    "\n",
    "* **training_data** List[List]: The data\n",
    "* **attribute_names** List: The attribute names of the data (22 for mushroom; size, shape, and color for the lecture)\n",
    "* **depth_limit** int: The depth limit of the tree\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **dt** Dict: The trained decision tree using the ID3 algorithm (entropy, information gain). It is represented as a nested dictionary. The dictionary returned for the lecture is structured as below:\n",
    "\n",
    "```\n",
    "{\n",
    "('size', 1, 'large'): \n",
    "    {('color', 2, 'blue'): 'no', \n",
    "     ('color', 2, 'green'): 'yes', \n",
    "     ('color', 2, 'red'): \n",
    "         {('shape', 0, 'round'): 'yes', \n",
    "          ('shape', 0, 'square'): 'no'}\n",
    "     }, \n",
    "('size', 1, 'small'): \n",
    "     {('shape', 0, 'square'): 'no', \n",
    "      ('shape', 0, 'round'): \n",
    "          {('color', 2, 'blue'): 'no', \n",
    "           ('color', 2, 'red'): 'yes', \n",
    "           ('color', 2, 'green'): 'no'}\n",
    "      }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "Notice that the keys are tuples; for instance, ('size', 1, 'large') is a key. The key includes the attribute's name, column number in data, and value.\n",
    "\n",
    "\n",
    "The function currently returns a hard-coded tree. Your implementation should replace this with a tree that is learned from the data using the ID3 algorithm. You do not have to assert test `train`, but it may be worthwhile to check that it can return the tree from the lecture once your implementation is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, attribute_names, depth_limit=None):\n",
    "    structured_data = get_structured_data(training_data, attribute_names)\n",
    "    decision_tree_root = id3(structured_data, attribute_names, get_mode(structured_data['y']), 0, depth_limit)\n",
    "    return dictionaried_tree(decision_tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_lecture = train(training_data=train_lecture, attribute_names=attribute_names_lecture, depth_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_prediction\"></a>\n",
    "## get_prediction\n",
    "\n",
    "This recursive function uses a decision tree represented as a nested dictionary get a prediction from a record, which is a row of the data. \n",
    "\n",
    "* **record** List[]: A row of data to be predicted\n",
    "* **dt** the decision tree used to make the prediction\n",
    "\n",
    "\n",
    "**returns** \n",
    "A prediction ('yes' or 'no' for instance, from our Self Check example.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(record, dt):\n",
    "    if not isinstance(dt, dict):\n",
    "        return dt\n",
    "    else:\n",
    "        for key, value in dt.items():\n",
    "            if record[key[1]]==key[2]:\n",
    "                return get_prediction(record, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "yes\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(['round','large','blue','no'], dt=dt_lecture))\n",
    "print(get_prediction(['square','large','green','yes'], dt=dt_lecture))\n",
    "print(get_prediction(['square','small','red','no'], dt=dt_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "\n",
    "This function takes a decision tree, observations, and a labeled flag to return a list of classifications. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **observation** List[List]: a list of items, where each item is a row of the data\n",
    "* **labeled** Bool: true for labeled data\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **y_hat** List: A list of classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dt, observations):\n",
    "    y_hat = []\n",
    "    for record in observations:\n",
    "        y_hat.append(get_prediction(record, dt))   \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(classify(dt=dt_lecture, observations=test_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## evaluate\n",
    "\n",
    "This function evaluates the performance of a classifier. It takes a data set (training set or test set) and the classification result (see [classify](#classify) above and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$ \n",
    "\n",
    "* **y_hat** List: A list of predictions\n",
    "* **observations** List[List]: Data to be predicted (typically training or test set)\n",
    "\n",
    "\n",
    "**returns** \n",
    "\n",
    "* **error_rate** float: The error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_hat, observations):\n",
    "    errors = 0\n",
    "    ground_truth = get_answers(observations)\n",
    "    for index in range(len(y_hat)):\n",
    "        if y_hat[index] != ground_truth[index]:\n",
    "            errors = errors + 1\n",
    "    return errors / (len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(classify(dt=dt_lecture, observations=data_lecture), observations=data_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_stats\"></a>\n",
    "## get_stats\n",
    "\n",
    "This function computes the mean and the standard deviation for a given list of observations. \n",
    "\n",
    "* **observations** List[float]: A list of observations\n",
    "\n",
    "\n",
    "**returns** (mean, standard deviation) Tuple[float,float]: tuple consisting of mean and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(observations: List[float]) -> Tuple[float,float]:\n",
    "    mean = sum(observations) / len(observations)\n",
    "    variance = sum([(elem - mean)**2 for elem in observations]) / len(observations)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_stats([2, 4, 4, 4, 5, 5, 7, 9]) == (5.0, 2.0)\n",
    "assert get_stats([1, 1, 1]) == (1.0, 0.0)\n",
    "assert get_stats([0]) == (0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validate\"></a>\n",
    "## cross_validate\n",
    "\n",
    "This function takes folds of data to `train`, `classify`, and `evaluate`.\n",
    "\n",
    "\n",
    "* **folds** List[List[List]]: The original dataset partitioned into folds (see `create_folds` above)\n",
    "* **attribute_names** int: the feature names\n",
    "* **hyperparameters** List: A list of hyperparameters to explore (depth limits for a decision tree, for instance)\n",
    "\n",
    "**returns** \n",
    "\n",
    "Nothing is returned, but for each hyperparameter setting, the function prints out the fold number and the error rate for that fold. The mean and variance is printed across folds for each hyperparameter setting. The error rates are reported in terms of percents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(folds, attribute_names, hyperparameters):\n",
    "    for hyperparameter in hyperparameters:\n",
    "        train_error, test_error  = [], []\n",
    "        error_list_train, error_list_test = [], []\n",
    "        for fold_index in range(len(folds)):\n",
    "            training_data, test_data = create_train_test(folds, fold_index)\n",
    "            tree = train(training_data=training_data, attribute_names=attribute_names, depth_limit=hyperparameter)\n",
    "            y_hat_train = classify(tree, training_data)\n",
    "            y_hat_test = classify(tree, test_data)\n",
    "            error_rate_train = evaluate(y_hat_train, training_data)\n",
    "            error_rate_test = evaluate(y_hat_test, test_data)\n",
    "            error_list_train.append(error_rate_train)\n",
    "            error_list_test.append(error_rate_test)\n",
    "            print(f\"Fold: {fold_index}\\tTrain Error: {error_rate_train*100:.2f}%\\tTest Error: {error_rate_test*100:.2f}%\")\n",
    "        print(f\"***\")\n",
    "        print(f\"Depth limit: {hyperparameter}\")\n",
    "        print(f\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Train Error: {get_stats(error_list_train)[0]*100:.2f}%({get_stats(error_list_train)[1]*100:.2f}%) Test Error: {get_stats(error_list_test)[0]*100:.2f}%({get_stats(error_list_test)[1]*100:.2f}%)\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 46.15%\tTest Error: 100.00%\n",
      "Fold: 3\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 38.46%\tTest Error: 100.00%\n",
      "Fold: 5\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 7\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 8\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 45.88%(3.53%) Test Error: 55.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 30.77%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 14.29%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "Fold: 9\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 22.20%(5.59%) Test Error: 45.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 7.69%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 15.38%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 7.14%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 14.29%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 14.29%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 8.96%(6.53%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_lecture, attribute_names=attribute_names_lecture, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pretty_print_tree\"></a>\n",
    "## pretty_print_tree\n",
    "\n",
    "This function provides a text-based representation of a decision tree that is represented as a nested dictionary. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **tab_space** Int: How much to tab successive depth levels of the resulting tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(dt, tab_space):\n",
    "    for key, value in dt.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \": \")\n",
    "            print(\"\\n\")\n",
    "            pretty_print_tree(value, tab_space+3)\n",
    "        else:\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \" =====> \" + str(value))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE - large: \n",
      "\n",
      "\n",
      "      COLOR - blue =====> no\n",
      "\n",
      "\n",
      "      COLOR - green =====> yes\n",
      "\n",
      "\n",
      "      COLOR - red: \n",
      "\n",
      "\n",
      "            SHAPE - round =====> yes\n",
      "\n",
      "\n",
      "            SHAPE - square =====> no\n",
      "\n",
      "\n",
      "SIZE - small: \n",
      "\n",
      "\n",
      "      SHAPE - round: \n",
      "\n",
      "\n",
      "            COLOR - blue =====> no\n",
      "\n",
      "\n",
      "            COLOR - green =====> no\n",
      "\n",
      "\n",
      "            COLOR - red =====> yes\n",
      "\n",
      "\n",
      "      SHAPE - square =====> no\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_lecture = train(training_data=data_lecture, attribute_names=attribute_names_lecture, depth_limit=None)\n",
    "pretty_print_tree(dt_lecture, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the Mushrooom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_mushroom = create_folds(data=data_mushroom, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 48.34%\tTest Error: 46.99%\n",
      "Fold: 1\tTrain Error: 48.63%\tTest Error: 44.40%\n",
      "Fold: 2\tTrain Error: 48.31%\tTest Error: 47.23%\n",
      "Fold: 3\tTrain Error: 48.08%\tTest Error: 49.32%\n",
      "Fold: 4\tTrain Error: 48.15%\tTest Error: 48.65%\n",
      "Fold: 5\tTrain Error: 48.06%\tTest Error: 49.51%\n",
      "Fold: 6\tTrain Error: 48.09%\tTest Error: 49.26%\n",
      "Fold: 7\tTrain Error: 48.22%\tTest Error: 48.03%\n",
      "Fold: 8\tTrain Error: 48.09%\tTest Error: 49.26%\n",
      "Fold: 9\tTrain Error: 48.07%\tTest Error: 49.38%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.20%(0.17%) Test Error: 48.20%(1.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 1.49%\tTest Error: 1.35%\n",
      "Fold: 1\tTrain Error: 1.55%\tTest Error: 0.86%\n",
      "Fold: 2\tTrain Error: 1.50%\tTest Error: 1.23%\n",
      "Fold: 3\tTrain Error: 1.38%\tTest Error: 2.34%\n",
      "Fold: 4\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "Fold: 5\tTrain Error: 1.48%\tTest Error: 1.48%\n",
      "Fold: 6\tTrain Error: 1.49%\tTest Error: 1.35%\n",
      "Fold: 7\tTrain Error: 1.42%\tTest Error: 1.97%\n",
      "Fold: 8\tTrain Error: 1.42%\tTest Error: 1.97%\n",
      "Fold: 9\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 1.48%(0.05%) Test Error: 1.48%(0.44%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.56%\tTest Error: 0.86%\n",
      "Fold: 1\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 2\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 3\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 4\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 5\tTrain Error: 0.57%\tTest Error: 0.74%\n",
      "Fold: 6\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 7\tTrain Error: 0.57%\tTest Error: 0.74%\n",
      "Fold: 8\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 9\tTrain Error: 0.62%\tTest Error: 0.37%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.59%(0.02%) Test Error: 0.59%(0.14%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 1\tTrain Error: 0.27%\tTest Error: 0.49%\n",
      "Fold: 2\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 3\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 4\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 5\tTrain Error: 0.26%\tTest Error: 0.62%\n",
      "Fold: 6\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 7\tTrain Error: 0.27%\tTest Error: 0.49%\n",
      "Fold: 8\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 9\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.30%(0.02%) Test Error: 0.30%(0.17%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_mushroom, attribute_names=attribute_names_mushroom, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Mushroom Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODOR - a =====> e\n",
      "\n",
      "\n",
      "ODOR - c =====> p\n",
      "\n",
      "\n",
      "ODOR - f =====> p\n",
      "\n",
      "\n",
      "ODOR - l =====> e\n",
      "\n",
      "\n",
      "ODOR - m =====> p\n",
      "\n",
      "\n",
      "ODOR - n: \n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - b =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - h =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - k =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - n =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - o =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - r =====> p\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - w: \n",
      "\n",
      "\n",
      "            HABITAT - d: \n",
      "\n",
      "\n",
      "                  GILL-SIZE - b =====> e\n",
      "\n",
      "\n",
      "                  GILL-SIZE - n =====> p\n",
      "\n",
      "\n",
      "            HABITAT - g =====> e\n",
      "\n",
      "\n",
      "            HABITAT - l: \n",
      "\n",
      "\n",
      "                  CAP-COLOR - c =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - n =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - w =====> p\n",
      "\n",
      "\n",
      "                  CAP-COLOR - y =====> p\n",
      "\n",
      "\n",
      "            HABITAT - p =====> e\n",
      "\n",
      "\n",
      "            HABITAT - w =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - y =====> e\n",
      "\n",
      "\n",
      "ODOR - p =====> p\n",
      "\n",
      "\n",
      "ODOR - s =====> p\n",
      "\n",
      "\n",
      "ODOR - y =====> p\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mushroom = train(training_data=data_mushroom, attribute_names=attribute_names_mushroom, depth_limit=None)\n",
    "pretty_print_tree(dt_mushroom, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL. BONUS. \n",
    "\n",
    "Use an AI/ML library to build a decision tree for the mushroom dataset. Explore different depth limits. Print results. Display the best tree using your chosen library.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
